from flask import Flask, render_template, request, jsonify, session
from datetime import datetime, timedelta
import json
import os
import pandas as pd
import numpy as np
import requests
from pathlib import Path
import tempfile
import logging
import uuid
import hashlib
import time
from functools import wraps
import importlib.util
import sys
from collections import Counter
import builtins
import re

app = Flask(__name__)
app.secret_key = os.environ.get('SECRET_KEY', 'lottopro-ai-v3-secret-key-2025')
app.config['JSON_AS_ASCII'] = False

# ë¡œê¹… ì„¤ì • - ë” ìƒì„¸í•œ ì •ë³´ í¬í•¨
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# GitHub ì„¤ì •
GITHUB_REPO = os.environ.get('GITHUB_REPO', 'kkbhong71/lottopro-ai-v3.0')
GITHUB_TOKEN = os.environ.get('GITHUB_TOKEN', '')
GITHUB_API_BASE = f'https://api.github.com/repos/{GITHUB_REPO}'

# ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰ ì œí•œ
ALGORITHM_CACHE = {}
LAST_EXECUTION = {}
EXECUTION_LIMIT = 60

# ğŸ†• ë°ì´í„° íë¦„ ê²€ì¦ì„ ìœ„í•œ ì „ì—­ ë³€ìˆ˜
DATA_FLOW_STATS = {
    'csv_load_time': None,
    'csv_load_success': False,
    'total_records': 0,
    'last_algorithm_execution': None,
    'data_validation_results': {}
}

def rate_limit(limit_seconds=60):
    """API í˜¸ì¶œ ì œí•œ ë°ì½”ë ˆì´í„°"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            key = f"{request.remote_addr}_{func.__name__}"
            now = time.time()
            
            if key in LAST_EXECUTION:
                if now - LAST_EXECUTION[key] < limit_seconds:
                    return jsonify({
                        'status': 'error', 
                        'message': f'{limit_seconds}ì´ˆ í›„ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.'
                    }), 429
            
            LAST_EXECUTION[key] = now
            return func(*args, **kwargs)
        return wrapper
    return decorator

@app.before_request
def ensure_session():
    """ëª¨ë“  ìš”ì²­ ì „ì— ì„¸ì…˜ ID í™•ì¸ ë° ìƒì„±"""
    if 'user_id' not in session:
        session['user_id'] = str(uuid.uuid4())
        logger.info(f"New user session created: {session['user_id']}")

class LottoProAI:
    def __init__(self):
        self.data_path = Path('data')
        self.data_path.mkdir(exist_ok=True)
        
        self.user_data_path = self.data_path / 'user_predictions.json'
        self.algorithm_info_path = Path('algorithms/algorithm_info.json')
        
        self.cache_path = self.data_path / 'cache'
        self.cache_path.mkdir(exist_ok=True)
        
        # ğŸ†• ë°ì´í„° ê²€ì¦ ê²°ê³¼ ì €ì¥
        self.data_validation = {
            'csv_found': False,
            'csv_path': None,
            'load_timestamp': None,
            'records_loaded': 0,
            'columns_verified': False,
            'data_quality': {}
        }
        
        self.load_algorithm_info()
        self.load_lotto_data()
        
    def load_algorithm_info(self):
        """ì•Œê³ ë¦¬ì¦˜ ì •ë³´ ë¡œë“œ"""
        try:
            with open(self.algorithm_info_path, 'r', encoding='utf-8') as f:
                self.algorithm_info = json.load(f)
            
            if 'algorithms' in self.algorithm_info:
                logger.info(f"âœ… Loaded {len(self.algorithm_info.get('algorithms', {}))} algorithms")
            else:
                logger.warning("âš ï¸ Converting old algorithm info format to new format")
                algorithms_dict = {}
                for key, value in self.algorithm_info.items():
                    if isinstance(value, dict) and 'name' in value:
                        algorithms_dict[key] = value
                
                self.algorithm_info = {
                    "version": "3.0",
                    "algorithms": algorithms_dict,
                    "categories": {},
                    "difficulty_levels": {}
                }
                logger.info(f"âœ… Converted {len(algorithms_dict)} algorithms")
                
        except FileNotFoundError:
            logger.warning("âš ï¸ Algorithm info file not found, using default")
            self.algorithm_info = {
                "version": "3.0",
                "algorithms": {},
                "categories": {},
                "difficulty_levels": {}
            }
            
    def load_lotto_data(self):
        """ë¡œë˜ ë‹¹ì²¨ë²ˆí˜¸ ë°ì´í„° ë¡œë“œ - ğŸ†• ê²€ì¦ ê¸°ëŠ¥ ê°•í™”"""
        try:
            # ì—¬ëŸ¬ ê°€ëŠ¥í•œ ê²½ë¡œ ì‹œë„
            possible_paths = [
                self.data_path / 'new_1194.csv',
                Path('data/new_1194.csv'),
                Path('new_1194.csv'),
                Path('/opt/render/project/src/data/new_1194.csv'),
                Path('/opt/render/project/src/new_1194.csv')
            ]
            
            csv_path = None
            logger.info("ğŸ” CSV íŒŒì¼ ê²€ìƒ‰ ì‹œì‘...")
            
            for path in possible_paths:
                logger.info(f"  ì‹œë„: {path}")
                if path.exists():
                    csv_path = path
                    logger.info(f"âœ… CSV íŒŒì¼ ë°œê²¬: {path}")
                    self.data_validation['csv_found'] = True
                    self.data_validation['csv_path'] = str(path)
                    break
            
            if csv_path is None:
                logger.error(f"âŒ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ. ì‹œë„í•œ ê²½ë¡œ:")
                for path in possible_paths:
                    logger.error(f"  - {path} (exists: {path.exists()})")
                raise FileNotFoundError("new_1194.csv íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            # CSV íŒŒì¼ ë¡œë“œ
            load_start_time = time.time()
            self.lotto_df = pd.read_csv(csv_path)
            load_duration = time.time() - load_start_time
            
            # ğŸ†• ê²€ì¦ 1: ê¸°ë³¸ ì •ë³´
            logger.info("=" * 70)
            logger.info("ğŸ“Š CSV ë°ì´í„° ë¡œë“œ ê²€ì¦")
            logger.info("=" * 70)
            logger.info(f"âœ… ë¡œë“œ ì‹œê°„: {load_duration:.3f}ì´ˆ")
            logger.info(f"âœ… ì´ íšŒì°¨: {len(self.lotto_df)}")
            logger.info(f"âœ… ì›ë³¸ ì»¬ëŸ¼: {list(self.lotto_df.columns)}")
            
            self.data_validation['load_timestamp'] = datetime.now().isoformat()
            self.data_validation['records_loaded'] = len(self.lotto_df)
            self.data_validation['load_duration'] = load_duration
            
            # ğŸ†• ê²€ì¦ 2: ìƒ˜í”Œ ë°ì´í„°
            if not self.lotto_df.empty:
                first_row = self.lotto_df.iloc[0].to_dict()
                last_row = self.lotto_df.iloc[-1].to_dict()
                logger.info(f"ğŸ² ì²« íšŒì°¨: {first_row}")
                logger.info(f"ğŸ² ìµœì‹  íšŒì°¨: {last_row}")
                
                self.data_validation['first_record'] = first_row
                self.data_validation['latest_record'] = last_row
            
            # ğŸ†• ê²€ì¦ 3: ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬
            expected_columns = ['round', 'draw date', 'num1', 'num2', 'num3', 'num4', 'num5', 'num6', 'bonus num']
            actual_columns = list(self.lotto_df.columns)
            
            logger.info(f"ğŸ“‹ ì»¬ëŸ¼ ê²€ì¦:")
            if actual_columns == expected_columns:
                logger.info(f"  âœ… ì»¬ëŸ¼ í˜•ì‹ ì •ìƒ")
                self.data_validation['columns_verified'] = True
            else:
                logger.warning(f"  âš ï¸ ì»¬ëŸ¼ëª… ë¶ˆì¼ì¹˜:")
                logger.warning(f"    ì˜ˆìƒ: {expected_columns}")
                logger.warning(f"    ì‹¤ì œ: {actual_columns}")
                self.data_validation['columns_verified'] = False
            
            # ğŸ†• ê²€ì¦ 4: ë²ˆí˜¸ ì»¬ëŸ¼ í’ˆì§ˆ
            number_cols = ['num1', 'num2', 'num3', 'num4', 'num5', 'num6']
            quality_report = {}
            
            logger.info(f"ğŸ”¢ ë²ˆí˜¸ ë°ì´í„° í’ˆì§ˆ:")
            for col in number_cols:
                if col in self.lotto_df.columns:
                    null_count = self.lotto_df[col].isnull().sum()
                    invalid_count = ((self.lotto_df[col] < 1) | (self.lotto_df[col] > 45)).sum()
                    valid_count = len(self.lotto_df) - null_count - invalid_count
                    
                    quality_report[col] = {
                        'total': len(self.lotto_df),
                        'valid': int(valid_count),
                        'null': int(null_count),
                        'out_of_range': int(invalid_count),
                        'quality_percentage': round(valid_count / len(self.lotto_df) * 100, 2)
                    }
                    
                    logger.info(f"  - {col}: ìœ íš¨={valid_count}, NULL={null_count}, ë²”ìœ„ì™¸={invalid_count} "
                              f"({quality_report[col]['quality_percentage']}% âœ…)")
                else:
                    logger.warning(f"  - {col}: âŒ ì»¬ëŸ¼ ì—†ìŒ!")
                    quality_report[col] = {'error': 'column_not_found'}
            
            self.data_validation['data_quality'] = quality_report
            
            # ğŸ†• ê²€ì¦ 5: í†µê³„ ìš”ì•½
            if all(col in self.lotto_df.columns for col in number_cols):
                logger.info(f"ğŸ“ˆ ë°ì´í„° í†µê³„:")
                for col in number_cols:
                    stats = self.lotto_df[col].describe()
                    logger.info(f"  - {col}: min={stats['min']}, max={stats['max']}, "
                              f"mean={stats['mean']:.2f}, std={stats['std']:.2f}")
            
            logger.info("=" * 70)
            logger.info(f"âœ… ë¡œë˜ ë°ì´í„° ë¡œë“œ ì™„ë£Œ - {len(self.lotto_df)}íšŒì°¨")
            logger.info("=" * 70)
            
            # ğŸ†• ì „ì—­ í†µê³„ ì—…ë°ì´íŠ¸
            DATA_FLOW_STATS['csv_load_time'] = datetime.now().isoformat()
            DATA_FLOW_STATS['csv_load_success'] = True
            DATA_FLOW_STATS['total_records'] = len(self.lotto_df)
            DATA_FLOW_STATS['data_validation_results'] = quality_report
                
        except FileNotFoundError as e:
            logger.error(f"âŒ CSV íŒŒì¼ ì—†ìŒ: {str(e)}")
            self.lotto_df = pd.DataFrame()
            self.data_validation['error'] = str(e)
            DATA_FLOW_STATS['csv_load_success'] = False
        except pd.errors.EmptyDataError:
            logger.error("âŒ CSV íŒŒì¼ì´ ë¹„ì–´ìˆìŒ")
            self.lotto_df = pd.DataFrame()
            self.data_validation['error'] = 'empty_csv'
            DATA_FLOW_STATS['csv_load_success'] = False
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}", exc_info=True)
            self.lotto_df = pd.DataFrame()
            self.data_validation['error'] = str(e)
            DATA_FLOW_STATS['csv_load_success'] = False
    
    def check_dangerous_code(self, code_content):
        """ê°œì„ ëœ ë³´ì•ˆ ê²€ì‚¬ - ì •ê·œí‘œí˜„ì‹ ì‚¬ìš©"""
        dangerous_patterns = [
            (r'\brm\s+-[rf]', 'Shell command: rm -rf (íŒŒì¼ ì‚­ì œ)'),
            (r'\bos\.system\s*\(', 'os.system() í˜¸ì¶œ'),
            (r'\bos\.remove\s*\(', 'os.remove() í˜¸ì¶œ'),
            (r'\bos\.rmdir\s*\(', 'os.rmdir() í˜¸ì¶œ'),
            (r'\bos\.unlink\s*\(', 'os.unlink() í˜¸ì¶œ'),
            (r'\bsubprocess\.', 'subprocess ëª¨ë“ˆ ì‚¬ìš©'),
            (r'\bshutil\.rmtree\s*\(', 'shutil.rmtree() í˜¸ì¶œ'),
            (r'\bexec\s*\(', 'exec() í˜¸ì¶œ'),
            (r'\beval\s*\(', 'eval() í˜¸ì¶œ'),
            (r'\b__import__\s*\(', 'ë™ì  import'),
            (r'\bopen\s*\([^)]*[\'"]w[\'"]', 'íŒŒì¼ ì“°ê¸° ëª¨ë“œ'),
        ]
        
        found_issues = []
        for pattern, description in dangerous_patterns:
            if re.search(pattern, code_content, re.IGNORECASE):
                found_issues.append(description)
                logger.warning(f"âš ï¸ Potentially dangerous pattern: {description}")
        
        return found_issues
    
    def get_algorithm_cache_key(self, algorithm_id):
        """ì•Œê³ ë¦¬ì¦˜ ìºì‹œ í‚¤ ìƒì„±"""
        data_hash = hashlib.md5(str(len(self.lotto_df)).encode()).hexdigest()[:8]
        return f"{algorithm_id}_{data_hash}"
    
    def execute_github_algorithm(self, algorithm_id, user_numbers=None):
        """GitHubì—ì„œ ì•Œê³ ë¦¬ì¦˜ ì½”ë“œë¥¼ ì•ˆì „í•˜ê²Œ ì‹¤í–‰ - ğŸ†• ê²€ì¦ ê¸°ëŠ¥ ê°•í™”"""
        execution_log = {
            'algorithm_id': algorithm_id,
            'start_time': datetime.now().isoformat(),
            'user_numbers': user_numbers,
            'data_transfer_verified': False,
            'execution_success': False
        }
        
        try:
            if algorithm_id not in self.algorithm_info.get('algorithms', {}):
                raise Exception(f"Algorithm '{algorithm_id}' not found")
            
            # ğŸ†• ê²€ì¦ 1: ë°ì´í„° ë¡œë“œ ìƒíƒœ í™•ì¸
            if self.lotto_df.empty:
                logger.error("âŒ ë¡œë˜ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŒ - ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰ ë¶ˆê°€")
                execution_log['error'] = 'empty_dataframe'
                raise Exception("ë¡œë˜ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            algorithm_info = self.algorithm_info['algorithms'][algorithm_id]
            
            # ìºì‹œ í™•ì¸
            if not user_numbers:
                cache_key = self.get_algorithm_cache_key(algorithm_id)
                cache_file = self.cache_path / f"{cache_key}.json"
                
                if cache_file.exists():
                    cache_time = datetime.fromtimestamp(cache_file.stat().st_mtime)
                    if datetime.now() - cache_time < timedelta(hours=1):
                        with open(cache_file, 'r', encoding='utf-8') as f:
                            cached_result = json.load(f)
                            cached_result['cached'] = True
                            logger.info(f"âœ… Cached result for {algorithm_id}")
                            return cached_result
            
            # GitHubì—ì„œ ì•Œê³ ë¦¬ì¦˜ ë‹¤ìš´ë¡œë“œ
            algorithm_path = algorithm_info.get('github_path', f'algorithms/{algorithm_id}.py')
            github_url = f'https://raw.githubusercontent.com/{GITHUB_REPO}/main/{algorithm_path}'
            
            headers = {}
            if GITHUB_TOKEN:
                headers['Authorization'] = f'token {GITHUB_TOKEN}'
            
            logger.info(f"ğŸ“¥ Downloading algorithm from: {github_url}")
            response = requests.get(github_url, headers=headers, timeout=30)
            
            if response.status_code != 200:
                raise Exception(f"Failed to download algorithm: HTTP {response.status_code}")
            
            code_content = response.text
            
            # ë³´ì•ˆ ê²€ì‚¬
            dangerous_issues = self.check_dangerous_code(code_content)
            if dangerous_issues:
                logger.warning(f"âš ï¸ Security check found {len(dangerous_issues)} potential issues in {algorithm_id}")
                for issue in dangerous_issues:
                    logger.warning(f"  - {issue}")
            
            # ğŸ†• ê²€ì¦ 2: ë°ì´í„° ì „ë‹¬ ì „ ë¡œê¹…
            logger.info("=" * 70)
            logger.info(f"ğŸš€ ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰ ì¤€ë¹„: {algorithm_id}")
            logger.info("=" * 70)
            logger.info(f"ğŸ“Š ì „ë‹¬í•  ë°ì´í„°:")
            logger.info(f"  - íšŒì°¨ ìˆ˜: {len(self.lotto_df)}")
            logger.info(f"  - ì»¬ëŸ¼: {list(self.lotto_df.columns)}")
            
            if not self.lotto_df.empty:
                latest_numbers = self.lotto_df.iloc[-1][['num1', 'num2', 'num3', 'num4', 'num5', 'num6']].tolist()
                logger.info(f"  - ìµœì‹  íšŒì°¨ ìƒ˜í”Œ: {latest_numbers}")
                execution_log['latest_sample'] = latest_numbers
            
            execution_log['data_rows'] = len(self.lotto_df)
            execution_log['data_columns'] = list(self.lotto_df.columns)
            
            # ğŸ†• ê²€ì¦ 3: ë””ë²„ê¹… ì½”ë“œ ì£¼ì…
            debug_code = """
# ===== ë°ì´í„° ìˆ˜ì‹  ê²€ì¦ ì½”ë“œ =====
import sys
_verification_passed = False

try:
    if 'lotto_data' in globals():
        print(f"âœ… [VERIFY] lotto_data ìˆ˜ì‹  ì„±ê³µ: {len(lotto_data)}íšŒì°¨")
        print(f"âœ… [VERIFY] ì»¬ëŸ¼: {list(lotto_data.columns)}")
        
        if not lotto_data.empty:
            sample_row = lotto_data.iloc[-1]
            sample_numbers = [sample_row['num1'], sample_row['num2'], sample_row['num3'], 
                            sample_row['num4'], sample_row['num5'], sample_row['num6']]
            print(f"âœ… [VERIFY] ìµœì‹  íšŒì°¨ ìƒ˜í”Œ: {sample_numbers}")
            _verification_passed = True
        else:
            print("âŒ [VERIFY] lotto_dataê°€ ë¹„ì–´ìˆìŒ!")
    else:
        print("âŒ [VERIFY] lotto_dataê°€ globals()ì— ì—†ìŒ!")
except Exception as e:
    print(f"âŒ [VERIFY] ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {str(e)}")

if not _verification_passed:
    print("âš ï¸ [VERIFY] ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨ - fallback ëª¨ë“œë¡œ ì „í™˜ ê°€ëŠ¥")

# ===== ê²€ì¦ ì½”ë“œ ë =====

"""
            
            # Safe globals êµ¬ì„±
            original_import = builtins.__import__
            
            def safe_import(name, *args, **kwargs):
                """ë³´ì•ˆì„ ìœ„í•´ ì œí•œëœ ëª¨ë“ˆë§Œ import í—ˆìš©"""
                allowed_modules = {
                    'random', 'math', 'datetime', 'collections', 
                    'itertools', 'functools', 're', 'statistics',
                    'operator', 'bisect', 'heapq', 'array',
                    'pandas', 'numpy', 'pd', 'np',
                    'warnings'
                }
                if name in allowed_modules:
                    return original_import(name, *args, **kwargs)
                raise ImportError(f"Module '{name}' is not allowed for security reasons")
            
            safe_globals = {
                '__builtins__': {
                    'len': len, 'range': range, 'enumerate': enumerate,
                    'zip': zip, 'map': map, 'filter': filter,
                    'sum': sum, 'max': max, 'min': min, 'abs': abs,
                    'round': round, 'int': int, 'float': float,
                    'str': str, 'list': list, 'dict': dict, 'set': set,
                    'tuple': tuple, 'bool': bool, 'type': type,
                    'sorted': sorted, 'reversed': reversed,
                    'any': any, 'all': all,
                    'isinstance': isinstance,
                    '__import__': safe_import,
                    '__build_class__': builtins.__build_class__,
                    '__name__': '__main__',
                    'print': print,
                    'globals': lambda: safe_globals,
                    'Exception': Exception,
                    'ValueError': ValueError,
                    'TypeError': TypeError,
                    'KeyError': KeyError,
                    'IndexError': IndexError,
                    'AttributeError': AttributeError,
                    'ImportError': ImportError,
                    'RuntimeError': RuntimeError,
                    'ZeroDivisionError': ZeroDivisionError,
                    'StopIteration': StopIteration,
                    'NameError': NameError,
                },
                'pd': pd,
                'np': np,
                'Counter': Counter,
                'lotto_data': self.lotto_df.copy(),  # â† CSV ë°ì´í„°ë¥¼ ì•Œê³ ë¦¬ì¦˜ì— ì „ë‹¬
                'data_path': str(self.data_path),
                'datetime': datetime,
                'random': np.random,
                'user_numbers': user_numbers or [],
                '__name__': '__main__',
            }
            
            execution_log['data_transfer_verified'] = True
            
            # ğŸ†• ë””ë²„ê¹… ì½”ë“œ + ì•Œê³ ë¦¬ì¦˜ ì½”ë“œ ì‹¤í–‰
            full_code = debug_code + code_content
            
            logger.info(f"âš™ï¸ Executing algorithm: {algorithm_id} (ë°ì´í„°: {len(self.lotto_df)}íšŒì°¨)")
            
            try:
                exec(full_code, safe_globals)
                execution_log['code_execution_success'] = True
            except SyntaxError as e:
                execution_log['syntax_error'] = str(e)
                raise Exception(f"Syntax error in algorithm code: {str(e)}")
            except Exception as e:
                execution_log['runtime_error'] = str(e)
                raise Exception(f"Runtime error: {str(e)}")
            
            # ê²°ê³¼ í•¨ìˆ˜ í˜¸ì¶œ
            result = None
            for func_name in ['predict_numbers', 'predict', 'generate_numbers', 'main']:
                if func_name in safe_globals:
                    logger.info(f"âœ… Calling function: {func_name}")
                    execution_log['function_called'] = func_name
                    
                    if user_numbers:
                        result = safe_globals[func_name](user_numbers)
                    else:
                        result = safe_globals[func_name]()
                    break
            
            if result is None:
                raise Exception("No prediction function found (tried: predict_numbers, predict, generate_numbers, main)")
            
            # ê²°ê³¼ ê²€ì¦
            if not isinstance(result, (list, tuple)) or len(result) != 6:
                raise Exception(f"Algorithm must return exactly 6 numbers, got {len(result) if isinstance(result, (list, tuple)) else 'non-list'}")
            
            if not all(isinstance(n, (int, np.integer)) and 1 <= n <= 45 for n in result):
                raise Exception("All numbers must be integers between 1 and 45")
            
            if len(set(result)) != 6:
                raise Exception("All numbers must be unique")
            
            execution_log['execution_success'] = True
            execution_log['result'] = list(map(int, result))
            
            prediction_result = {
                'status': 'success',
                'numbers': sorted(list(map(int, result))),
                'algorithm': algorithm_id,
                'algorithm_name': algorithm_info.get('name', algorithm_id),
                'accuracy_rate': algorithm_info.get('accuracy_rate', algorithm_info.get('accuracy', 0)),
                'timestamp': datetime.now().isoformat(),
                'cached': False,
                'execution_log': execution_log  # ğŸ†• ì‹¤í–‰ ë¡œê·¸ í¬í•¨
            }
            
            # ìºì‹œ ì €ì¥
            if not user_numbers:
                cache_file = self.cache_path / f"{self.get_algorithm_cache_key(algorithm_id)}.json"
                with open(cache_file, 'w', encoding='utf-8') as f:
                    json.dump(prediction_result, f, ensure_ascii=False, indent=2)
                logger.info(f"ğŸ’¾ Cached result for {algorithm_id}")
            
            # ğŸ†• ì „ì—­ í†µê³„ ì—…ë°ì´íŠ¸
            DATA_FLOW_STATS['last_algorithm_execution'] = {
                'algorithm_id': algorithm_id,
                'timestamp': datetime.now().isoformat(),
                'success': True
            }
            
            logger.info("=" * 70)
            logger.info(f"âœ… ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰ ì™„ë£Œ: {prediction_result['numbers']}")
            logger.info("=" * 70)
            
            return prediction_result
                
        except requests.RequestException as e:
            logger.error(f"âŒ Network error downloading algorithm: {str(e)}")
            execution_log['error'] = f'network_error: {str(e)}'
            DATA_FLOW_STATS['last_algorithm_execution'] = {
                'algorithm_id': algorithm_id,
                'timestamp': datetime.now().isoformat(),
                'success': False,
                'error': str(e)
            }
            return {
                'status': 'error',
                'message': f'ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {str(e)}',
                'algorithm': algorithm_id,
                'execution_log': execution_log
            }
        except Exception as e:
            logger.error(f"âŒ Algorithm execution failed: {str(e)}", exc_info=True)
            execution_log['error'] = str(e)
            DATA_FLOW_STATS['last_algorithm_execution'] = {
                'algorithm_id': algorithm_id,
                'timestamp': datetime.now().isoformat(),
                'success': False,
                'error': str(e)
            }
            return {
                'status': 'error',
                'message': str(e),
                'algorithm': algorithm_id,
                'execution_log': execution_log
            }
    
    def save_user_prediction(self, user_id, prediction_data):
        """ì‚¬ìš©ì ì˜ˆì¸¡ ì €ì¥"""
        try:
            if self.user_data_path.exists():
                with open(self.user_data_path, 'r', encoding='utf-8') as f:
                    user_data = json.load(f)
            else:
                user_data = {}
            
            if user_id not in user_data:
                user_data[user_id] = {
                    'created_at': datetime.now().isoformat(),
                    'predictions': [],
                    'stats': {
                        'total_predictions': 0,
                        'total_matches': 0,
                        'best_match': 0,
                        'algorithm_usage': {}
                    }
                }
            
            prediction_entry = {
                'id': str(uuid.uuid4()),
                'numbers': prediction_data['numbers'],
                'algorithm': prediction_data['algorithm'],
                'algorithm_name': prediction_data.get('algorithm_name', ''),
                'timestamp': prediction_data.get('timestamp', datetime.now().isoformat()),
                'round_predicted': prediction_data.get('round_predicted', 1194),
                'is_checked': False,
                'match_result': None,
                'cached': prediction_data.get('cached', False)
            }
            
            user_data[user_id]['predictions'].append(prediction_entry)
            user_data[user_id]['stats']['total_predictions'] += 1
            
            algo_stats = user_data[user_id]['stats']['algorithm_usage']
            algo_id = prediction_data['algorithm']
            algo_stats[algo_id] = algo_stats.get(algo_id, 0) + 1
            
            with open(self.user_data_path, 'w', encoding='utf-8') as f:
                json.dump(user_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ğŸ’¾ Prediction saved for user {user_id}: {prediction_entry['id']}")
            
            return {'status': 'success', 'prediction_id': prediction_entry['id']}
            
        except Exception as e:
            logger.error(f"âŒ Failed to save prediction: {str(e)}")
            return {'status': 'error', 'message': str(e)}
    
    def delete_user_prediction(self, user_id, prediction_id):
        """ì‚¬ìš©ì ì˜ˆì¸¡ ì‚­ì œ"""
        try:
            if not self.user_data_path.exists():
                return {'status': 'error', 'message': 'No predictions found'}
            
            with open(self.user_data_path, 'r', encoding='utf-8') as f:
                user_data = json.load(f)
            
            if user_id not in user_data:
                return {'status': 'error', 'message': 'User not found'}
            
            predictions = user_data[user_id]['predictions']
            original_count = len(predictions)
            
            user_data[user_id]['predictions'] = [p for p in predictions if p['id'] != prediction_id]
            
            if len(user_data[user_id]['predictions']) == original_count:
                return {'status': 'error', 'message': 'Prediction not found'}
            
            user_data[user_id]['stats']['total_predictions'] = len(user_data[user_id]['predictions'])
            
            with open(self.user_data_path, 'w', encoding='utf-8') as f:
                json.dump(user_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ğŸ—‘ï¸ Prediction {prediction_id} deleted for user {user_id}")
            
            return {'status': 'success', 'message': 'Prediction deleted'}
            
        except Exception as e:
            logger.error(f"âŒ Failed to delete prediction: {str(e)}")
            return {'status': 'error', 'message': str(e)}
    
    def compare_with_winning_numbers(self, user_id, prediction_id, winning_numbers):
        """ë‹¹ì²¨ë²ˆí˜¸ì™€ ë¹„êµ"""
        try:
            with open(self.user_data_path, 'r', encoding='utf-8') as f:
                user_data = json.load(f)
            
            if user_id not in user_data:
                return {'status': 'error', 'message': 'User not found'}
            
            prediction = None
            for pred in user_data[user_id]['predictions']:
                if pred['id'] == prediction_id:
                    prediction = pred
                    break
            
            if not prediction:
                return {'status': 'error', 'message': 'Prediction not found'}
            
            predicted_numbers = set(prediction['numbers'])
            winning_set = set(winning_numbers[:6])
            matches = len(predicted_numbers.intersection(winning_set))
            
            prize_info = {
                6: {'rank': '1ë“±', 'description': '6ê°œ ì¼ì¹˜'},
                5: {'rank': '2ë“±', 'description': '5ê°œ ì¼ì¹˜'},
                4: {'rank': '3ë“±', 'description': '4ê°œ ì¼ì¹˜'},
                3: {'rank': '4ë“±', 'description': '3ê°œ ì¼ì¹˜'},
                2: {'rank': '5ë“±', 'description': '2ê°œ ì¼ì¹˜'},
                1: {'rank': '6ë“±', 'description': '1ê°œ ì¼ì¹˜'},
                0: {'rank': 'ë‚™ì²¨', 'description': 'ì¼ì¹˜ ì—†ìŒ'}
            }
            
            prediction['is_checked'] = True
            prediction['match_result'] = {
                'matches': matches,
                'winning_numbers': winning_numbers,
                'matched_numbers': sorted(list(predicted_numbers.intersection(winning_set))),
                'prize_info': prize_info.get(matches, prize_info[0]),
                'check_date': datetime.now().isoformat()
            }
            
            user_data[user_id]['stats']['total_matches'] += matches
            if matches > user_data[user_id]['stats']['best_match']:
                user_data[user_id]['stats']['best_match'] = matches
            
            with open(self.user_data_path, 'w', encoding='utf-8') as f:
                json.dump(user_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ğŸ¯ Comparison completed for prediction {prediction_id}: {matches} matches")
            
            return {
                'status': 'success',
                'matches': matches,
                'result': prediction['match_result']
            }
            
        except Exception as e:
            logger.error(f"âŒ Comparison failed: {str(e)}")
            return {'status': 'error', 'message': str(e)}

lotto_ai = LottoProAI()

@app.route('/')
def index():
    """ë©”ì¸ í˜ì´ì§€"""
    algorithm_count = len(lotto_ai.algorithm_info.get('algorithms', {}))
    data_count = len(lotto_ai.lotto_df) if not lotto_ai.lotto_df.empty else 0
    
    return render_template('index.html', 
                         algorithm_count=algorithm_count,
                         data_count=data_count,
                         latest_round=1194,
                         version="3.0")

@app.route('/algorithms')
def algorithms():
    """ì•Œê³ ë¦¬ì¦˜ ì„ íƒ í˜ì´ì§€"""
    algorithms_data = lotto_ai.algorithm_info.get('algorithms', {})
    categories = lotto_ai.algorithm_info.get('categories', {})
    difficulty_levels = lotto_ai.algorithm_info.get('difficulty_levels', {})
    
    return render_template('algorithm.html', 
                         algorithms=algorithms_data,
                         categories=categories,
                         difficulty_levels=difficulty_levels)

@app.route('/api/execute/<algorithm_id>')
@rate_limit(60)
def execute_algorithm(algorithm_id):
    """ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰ API (GET)"""
    if algorithm_id not in lotto_ai.algorithm_info.get('algorithms', {}):
        return jsonify({'status': 'error', 'message': 'Algorithm not found'}), 404
    
    result = lotto_ai.execute_github_algorithm(algorithm_id)
    return jsonify(result)

@app.route('/api/predict', methods=['POST'])
@rate_limit(60)
def predict_numbers():
    """ì•Œê³ ë¦¬ì¦˜ ì˜ˆì¸¡ API (POST)"""
    try:
        data = request.get_json()
        
        if not data:
            return jsonify({
                'status': 'error',
                'message': 'No data provided'
            }), 400
        
        algorithm_id = data.get('algorithm')
        user_numbers = data.get('user_numbers', [])
        
        if not algorithm_id:
            return jsonify({
                'status': 'error',
                'message': 'Algorithm ID is required'
            }), 400
        
        if algorithm_id not in lotto_ai.algorithm_info.get('algorithms', {}):
            return jsonify({
                'status': 'error',
                'message': f'Algorithm "{algorithm_id}" not found'
            }), 404
        
        if user_numbers:
            if not isinstance(user_numbers, list):
                return jsonify({
                    'status': 'error',
                    'message': 'user_numbers must be a list'
                }), 400
            
            if not all(isinstance(n, int) and 1 <= n <= 45 for n in user_numbers):
                return jsonify({
                    'status': 'error',
                    'message': 'All user numbers must be integers between 1 and 45'
                }), 400
            
            if len(set(user_numbers)) != len(user_numbers):
                return jsonify({
                    'status': 'error',
                    'message': 'User numbers must be unique'
                }), 400
        
        result = lotto_ai.execute_github_algorithm(algorithm_id, user_numbers)
        
        return jsonify(result)
        
    except Exception as e:
        logger.error(f"âŒ Predict API error: {str(e)}", exc_info=True)
        return jsonify({
            'status': 'error',
            'message': f'Internal server error: {str(e)}'
        }), 500

@app.route('/api/save-prediction', methods=['POST'])
def save_prediction():
    """ì˜ˆì¸¡ ì €ì¥ API"""
    try:
        data = request.get_json()
        
        if not data:
            return jsonify({'status': 'error', 'message': 'No data provided'}), 400
        
        user_id = session.get('user_id')
        if not user_id:
            return jsonify({'status': 'error', 'message': 'Session not found'}), 401
        
        required_fields = ['numbers', 'algorithm']
        for field in required_fields:
            if field not in data:
                return jsonify({'status': 'error', 'message': f'Missing field: {field}'}), 400
        
        result = lotto_ai.save_user_prediction(user_id, data)
        
        if result['status'] == 'success':
            return jsonify(result), 200
        else:
            return jsonify(result), 500
            
    except Exception as e:
        logger.error(f"âŒ Save prediction error: {str(e)}", exc_info=True)
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/delete-prediction', methods=['POST'])
def delete_prediction():
    """ì˜ˆì¸¡ ì‚­ì œ API"""
    try:
        data = request.get_json()
        
        if not data or 'prediction_id' not in data:
            return jsonify({'status': 'error', 'message': 'prediction_id is required'}), 400
        
        user_id = session.get('user_id')
        if not user_id:
            return jsonify({'status': 'error', 'message': 'Session not found'}), 401
        
        result = lotto_ai.delete_user_prediction(user_id, data['prediction_id'])
        
        if result['status'] == 'success':
            return jsonify(result), 200
        else:
            return jsonify(result), 404
            
    except Exception as e:
        logger.error(f"âŒ Delete prediction error: {str(e)}", exc_info=True)
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/compare-numbers', methods=['POST'])
def compare_numbers():
    """ë‹¹ì²¨ë²ˆí˜¸ ë¹„êµ API"""
    try:
        data = request.get_json()
        
        user_id = session.get('user_id')
        if not user_id:
            return jsonify({'status': 'error', 'message': 'User session not found'}), 401
        
        if not data or 'winning_numbers' not in data or 'prediction_id' not in data:
            return jsonify({'status': 'error', 'message': 'Invalid request data'}), 400
        
        winning_numbers = data.get('winning_numbers', [])
        if not isinstance(winning_numbers, list) or len(winning_numbers) < 6:
            return jsonify({'status': 'error', 'message': 'Invalid winning numbers'}), 400
        
        result = lotto_ai.compare_with_winning_numbers(
            user_id, 
            data['prediction_id'], 
            winning_numbers
        )
        
        if result['status'] == 'success':
            return jsonify(result), 200
        else:
            return jsonify(result), 404
            
    except Exception as e:
        logger.error(f"âŒ Compare numbers error: {str(e)}", exc_info=True)
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/user-predictions')
def get_user_predictions():
    """ì‚¬ìš©ì ì˜ˆì¸¡ ëª©ë¡ ì¡°íšŒ"""
    user_id = session.get('user_id')
    if not user_id:
        return jsonify({
            'predictions': [], 
            'stats': {
                'total_predictions': 0, 
                'total_matches': 0, 
                'best_match': 0,
                'algorithm_usage': {}
            }
        })
    
    try:
        if lotto_ai.user_data_path.exists():
            with open(lotto_ai.user_data_path, 'r', encoding='utf-8') as f:
                user_data = json.load(f)
                user_info = user_data.get(user_id, {
                    'predictions': [], 
                    'stats': {
                        'total_predictions': 0, 
                        'total_matches': 0, 
                        'best_match': 0,
                        'algorithm_usage': {}
                    }
                })
                return jsonify(user_info)
    except Exception as e:
        logger.error(f"âŒ Failed to load user predictions: {str(e)}")
    
    return jsonify({
        'predictions': [], 
        'stats': {
            'total_predictions': 0, 
            'total_matches': 0, 
            'best_match': 0,
            'algorithm_usage': {}
        }
    })

@app.route('/saved-numbers')
def saved_numbers():
    """ì €ì¥ëœ ë²ˆí˜¸ ê´€ë¦¬ í˜ì´ì§€"""
    return render_template('saved_numbers.html')

@app.route('/compare')
def compare():
    """ë‹¹ì²¨ë²ˆí˜¸ ë¹„êµ í˜ì´ì§€"""
    return render_template('compare.html')

@app.route('/statistics')
def statistics():
    """í†µê³„ ë¶„ì„ í˜ì´ì§€"""
    return render_template('statistics.html')

@app.route('/api/lottery-data')
def get_lottery_data():
    """ë¡œë˜ ë°ì´í„° API"""
    try:
        if lotto_ai.lotto_df.empty:
            return jsonify({
                'status': 'error',
                'message': 'No lottery data available'
            })
            
        return jsonify({
            'status': 'success',
            'data': lotto_ai.lotto_df.to_dict('records'),
            'total_records': len(lotto_ai.lotto_df),
            'latest_round': 1194
        })
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)})

@app.route('/api/algorithm-info')
def get_all_algorithm_info():
    """ì „ì²´ ì•Œê³ ë¦¬ì¦˜ ì •ë³´ ì¡°íšŒ"""
    try:
        algorithms = lotto_ai.algorithm_info.get('algorithms', {})
        
        unique_algorithms = {}
        for key, value in algorithms.items():
            if key not in unique_algorithms:
                unique_algorithms[key] = value
        
        return jsonify({
            'status': 'success',
            'info': unique_algorithms,
            'count': len(unique_algorithms),
            'latest_round': 1194,
            'timestamp': datetime.now().isoformat()
        })
    except Exception as e:
        logger.error(f"âŒ Failed to get algorithm info: {str(e)}")
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

@app.route('/api/algorithm-info/<algorithm_id>')
def get_algorithm_info(algorithm_id):
    """íŠ¹ì • ì•Œê³ ë¦¬ì¦˜ ì •ë³´ ì¡°íšŒ"""
    algorithms = lotto_ai.algorithm_info.get('algorithms', {})
    if algorithm_id not in algorithms:
        return jsonify({'status': 'error', 'message': 'Algorithm not found'}), 404
    
    return jsonify({
        'status': 'success',
        'algorithm': algorithms[algorithm_id]
    })

# ğŸ†• ===== ê²€ì¦ìš© API ì—”ë“œí¬ì¸íŠ¸ =====

@app.route('/api/debug/data-flow')
def debug_data_flow():
    """ğŸ†• ë°ì´í„° íë¦„ ë””ë²„ê¹… API - ì „ì²´ íŒŒì´í”„ë¼ì¸ ê²€ì¦"""
    try:
        result = {
            'timestamp': datetime.now().isoformat(),
            'version': '3.0',
            'steps': []
        }
        
        # Step 1: CSV ë¡œë“œ ìƒíƒœ
        step1 = {
            'step': 1,
            'name': 'CSV íŒŒì¼ ë¡œë“œ',
            'status': 'success' if not lotto_ai.lotto_df.empty else 'failed',
            'data_count': len(lotto_ai.lotto_df),
            'columns': list(lotto_ai.lotto_df.columns) if not lotto_ai.lotto_df.empty else [],
            'validation': lotto_ai.data_validation
        }
        
        if not lotto_ai.lotto_df.empty:
            step1['first_record'] = lotto_ai.lotto_df.iloc[0].to_dict()
            step1['latest_record'] = lotto_ai.lotto_df.iloc[-1].to_dict()
        
        result['steps'].append(step1)
        
        # Step 2: ë°ì´í„° í’ˆì§ˆ
        if not lotto_ai.lotto_df.empty:
            number_cols = ['num1', 'num2', 'num3', 'num4', 'num5', 'num6']
            quality_check = {}
            
            for col in number_cols:
                if col in lotto_ai.lotto_df.columns:
                    quality_check[col] = {
                        'null_count': int(lotto_ai.lotto_df[col].isnull().sum()),
                        'valid_range': int(((lotto_ai.lotto_df[col] >= 1) & (lotto_ai.lotto_df[col] <= 45)).sum()),
                        'total': len(lotto_ai.lotto_df),
                        'quality_percentage': round(
                            ((lotto_ai.lotto_df[col] >= 1) & (lotto_ai.lotto_df[col] <= 45)).sum() / len(lotto_ai.lotto_df) * 100, 
                            2
                        )
                    }
            
            step2 = {
                'step': 2,
                'name': 'ë°ì´í„° í’ˆì§ˆ í™•ì¸',
                'status': 'success',
                'quality_check': quality_check
            }
            result['steps'].append(step2)
        
        # Step 3: ì•Œê³ ë¦¬ì¦˜ ë¡œë“œ ìƒíƒœ
        step3 = {
            'step': 3,
            'name': 'ì•Œê³ ë¦¬ì¦˜ ë¡œë“œ ìƒíƒœ',
            'status': 'success',
            'algorithm_count': len(lotto_ai.algorithm_info.get('algorithms', {})),
            'algorithms': list(lotto_ai.algorithm_info.get('algorithms', {}).keys())
        }
        result['steps'].append(step3)
        
        # Step 4: ì „ì—­ í†µê³„
        step4 = {
            'step': 4,
            'name': 'ì „ì—­ ë°ì´í„° íë¦„ í†µê³„',
            'status': 'success',
            'global_stats': DATA_FLOW_STATS
        }
        result['steps'].append(step4)
        
        return jsonify(result)
        
    except Exception as e:
        logger.error(f"âŒ Debug API error: {str(e)}", exc_info=True)
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

@app.route('/api/debug/verify-csv')
def verify_csv():
    """ğŸ†• CSV íŒŒì¼ ì§ì ‘ ê²€ì¦ API"""
    try:
        verification = {
            'timestamp': datetime.now().isoformat(),
            'csv_path_tested': [],
            'csv_found': False,
            'csv_path': None,
            'file_info': {}
        }
        
        possible_paths = [
            Path('data/new_1194.csv'),
            Path('new_1194.csv'),
            Path('/opt/render/project/src/data/new_1194.csv'),
            Path('/opt/render/project/src/new_1194.csv')
        ]
        
        for path in possible_paths:
            path_info = {
                'path': str(path),
                'exists': path.exists(),
                'is_file': path.is_file() if path.exists() else False,
                'size': path.stat().st_size if path.exists() else 0
            }
            
            verification['csv_path_tested'].append(path_info)
            
            if path.exists():
                verification['csv_found'] = True
                verification['csv_path'] = str(path)
                
                # íŒŒì¼ ìƒì„¸ ì •ë³´
                stat = path.stat()
                verification['file_info'] = {
                    'size_bytes': stat.st_size,
                    'size_kb': round(stat.st_size / 1024, 2),
                    'modified': datetime.fromtimestamp(stat.st_mtime).isoformat(),
                    'readable': os.access(path, os.R_OK)
                }
                
                # ê°„ë‹¨í•œ ë¡œë“œ í…ŒìŠ¤íŠ¸
                try:
                    test_df = pd.read_csv(path, nrows=5)
                    verification['load_test'] = {
                        'success': True,
                        'sample_rows': len(test_df),
                        'columns': list(test_df.columns),
                        'first_row': test_df.iloc[0].to_dict() if not test_df.empty else {}
                    }
                except Exception as load_error:
                    verification['load_test'] = {
                        'success': False,
                        'error': str(load_error)
                    }
                
                break
        
        return jsonify(verification)
        
    except Exception as e:
        logger.error(f"âŒ CSV Verify error: {str(e)}", exc_info=True)
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

@app.route('/api/health')
def health_check():
    """ğŸ”„ ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸ - ê²€ì¦ ì •ë³´ ê°•í™”"""
    return jsonify({
        'status': 'healthy',
        'timestamp': datetime.now().isoformat(),
        'algorithms_loaded': len(lotto_ai.algorithm_info.get('algorithms', {})),
        'data_records': len(lotto_ai.lotto_df) if not lotto_ai.lotto_df.empty else 0,
        'csv_load_success': not lotto_ai.lotto_df.empty,
        'csv_validation': lotto_ai.data_validation,
        'latest_round': 1194,
        'version': '3.0',
        'session_active': 'user_id' in session,
        'data_flow_stats': DATA_FLOW_STATS
    })

# ğŸ†• ===== ê²€ì¦ìš© API ì—”ë“œí¬ì¸íŠ¸ ë =====

@app.errorhandler(404)
def not_found(error):
    if request.path.startswith('/api/'):
        return jsonify({
            'status': 'error',
            'message': 'API endpoint not found'
        }), 404
    try:
        return render_template('404.html'), 404
    except:
        return jsonify({'status': 'error', 'message': 'Page not found'}), 404

@app.errorhandler(500)
def internal_error(error):
    logger.error(f"âŒ Internal server error: {str(error)}", exc_info=True)
    if request.path.startswith('/api/'):
        return jsonify({
            'status': 'error',
            'message': 'Internal server error'
        }), 500
    try:
        return render_template('500.html'), 500
    except:
        return jsonify({'status': 'error', 'message': 'Internal server error'}), 500

@app.after_request
def after_request(response):
    """ëª¨ë“  ì‘ë‹µì— CORS í—¤ë” ì¶”ê°€"""
    response.headers.add('Access-Control-Allow-Origin', '*')
    response.headers.add('Access-Control-Allow-Headers', 'Content-Type,Authorization')
    response.headers.add('Access-Control-Allow-Methods', 'GET,POST,PUT,DELETE,OPTIONS')
    return response

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    debug_mode = os.environ.get('FLASK_DEBUG', 'False').lower() == 'true'
    
    logger.info("=" * 70)
    logger.info(f"ğŸš€ Starting LottoPro-AI v3.0 server on port {port}")
    logger.info("=" * 70)
    logger.info(f"ğŸ“ Debug mode: {debug_mode}")
    logger.info(f"ğŸ¤– Algorithms loaded: {len(lotto_ai.algorithm_info.get('algorithms', {}))}")
    logger.info(f"ğŸ“Š Lottery data records: {len(lotto_ai.lotto_df) if not lotto_ai.lotto_df.empty else 0}")
    logger.info(f"ğŸ¯ Latest round: 1194")
    logger.info(f"âœ… CSV load status: {'SUCCESS' if not lotto_ai.lotto_df.empty else 'FAILED'}")
    
    if not lotto_ai.lotto_df.empty:
        logger.info(f"ğŸ“‚ CSV path: {lotto_ai.data_validation.get('csv_path', 'Unknown')}")
        logger.info(f"ğŸ”¢ Data quality: {len([k for k, v in lotto_ai.data_validation.get('data_quality', {}).items() if v.get('quality_percentage', 0) > 99])} / 6 columns perfect")
    
    logger.info("=" * 70)
    logger.info("ğŸ” Debug APIs available:")
    logger.info("  - GET /api/debug/data-flow  : ì „ì²´ ë°ì´í„° íë¦„ ê²€ì¦")
    logger.info("  - GET /api/debug/verify-csv : CSV íŒŒì¼ ì§ì ‘ ê²€ì¦")
    logger.info("  - GET /api/health           : ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸ (ê²€ì¦ ì •ë³´ í¬í•¨)")
    logger.info("=" * 70)
    
    app.run(host='0.0.0.0', port=port, debug=debug_mode)
